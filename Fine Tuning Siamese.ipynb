{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Damage detection and recognition training pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define run parameters\n",
        "The dataset should follow the VGGFace2/ImageNet-style directory layout. Modify data_dir to the location of the dataset on wish to finetune on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from facenet_pytorch import InceptionResnetV1, fixed_image_standardization, training\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import os\n",
        "# from PIL import Image\n",
        "# import copy\n",
        "# import random\n",
        "from functions import SiameseInceptionResnetV1, siamese_dataset, pass_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"C:/Users/U339700/Documents/Palas/dataset/prueba_siamesas/crop_2class_train\"\n",
        "val_dir = \"C:/Users/U339700/Documents/Palas/dataset/prueba_siamesas/crop_2class_val\"\n",
        "model_dir = 'C:/Users/U339700/Documents/Palas/models'\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 8\n",
        "save_after = 1\n",
        "workers = 0 if os.name == 'nt' else 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Determine if an nvidia GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Inception Resnet V1 module\n",
        "See help(InceptionResnetV1) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "trans = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "data_augm_horz = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=1),\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "data_augm_vert = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomVerticalFlip(p=1),\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "data_augm_persp = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "data_augm_eq = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomEqualize(p=1),\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "data_augm_blur = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "data_augm_horz_vert = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=1),\n",
        "    transforms.RandomVerticalFlip(p=1),\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "data_augm_horz_blur = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=1),\n",
        "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "data_augm_vert_blur = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomVerticalFlip(p=1),\n",
        "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "data_augm_horz_vert_blur = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=1),\n",
        "    transforms.RandomVerticalFlip(p=1),\n",
        "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = siamese_dataset(data_dir, shuffle_pairs=True)\n",
        "val_dataset = siamese_dataset(val_dir, shuffle_pairs=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "siamese = SiameseInceptionResnetV1(\n",
        "    classify=False,\n",
        "    pretrained='vggface2',\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[tensor([[[[ 0.3867,  0.3867,  0.3867,  ...,  0.3867,  0.3867,  0.3867],\n",
              "            [ 0.3867,  0.3867,  0.3867,  ...,  0.3867,  0.3867,  0.3867],\n",
              "            [ 0.4023,  0.4023,  0.4023,  ...,  0.3867,  0.3789,  0.3789],\n",
              "            ...,\n",
              "            [ 0.3867,  0.3867,  0.3945,  ...,  0.3867,  0.3867,  0.3867],\n",
              "            [ 0.3867,  0.3867,  0.3945,  ...,  0.3789,  0.3711,  0.3789],\n",
              "            [ 0.3945,  0.3945,  0.3945,  ...,  0.3789,  0.3711,  0.3711]],\n",
              "  \n",
              "           [[ 0.3945,  0.3945,  0.3945,  ...,  0.4023,  0.4023,  0.4023],\n",
              "            [ 0.3867,  0.3945,  0.3945,  ...,  0.4023,  0.4023,  0.4023],\n",
              "            [ 0.3945,  0.3945,  0.3945,  ...,  0.4023,  0.3945,  0.3945],\n",
              "            ...,\n",
              "            [ 0.3789,  0.3789,  0.3867,  ...,  0.3867,  0.3867,  0.3867],\n",
              "            [ 0.3789,  0.3789,  0.3867,  ...,  0.3789,  0.3789,  0.3789],\n",
              "            [ 0.3867,  0.3867,  0.3867,  ...,  0.3867,  0.3867,  0.3867]],\n",
              "  \n",
              "           [[ 0.2539,  0.2539,  0.2539,  ...,  0.3008,  0.3008,  0.3008],\n",
              "            [ 0.2461,  0.2539,  0.2539,  ...,  0.3008,  0.3008,  0.3008],\n",
              "            [ 0.2539,  0.2539,  0.2539,  ...,  0.3086,  0.3008,  0.3008],\n",
              "            ...,\n",
              "            [ 0.2383,  0.2383,  0.2461,  ...,  0.2930,  0.2930,  0.2930],\n",
              "            [ 0.2383,  0.2383,  0.2461,  ...,  0.2852,  0.2773,  0.2852],\n",
              "            [ 0.2461,  0.2461,  0.2461,  ...,  0.2852,  0.2852,  0.3008]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.1445, -0.1445, -0.1523,  ...,  0.0430,  0.0430,  0.0352],\n",
              "            [-0.1523, -0.1523, -0.1523,  ...,  0.0430,  0.0430,  0.0430],\n",
              "            [-0.1523, -0.1523, -0.1523,  ...,  0.0430,  0.0430,  0.0430],\n",
              "            ...,\n",
              "            [-0.1133, -0.1133, -0.1133,  ...,  0.0352,  0.0352,  0.0352],\n",
              "            [-0.1211, -0.1211, -0.1211,  ...,  0.0352,  0.0352,  0.0352],\n",
              "            [-0.1211, -0.1211, -0.1211,  ...,  0.0352,  0.0352,  0.0352]],\n",
              "  \n",
              "           [[ 0.2070,  0.2070,  0.1992,  ...,  0.0273,  0.0273,  0.0195],\n",
              "            [ 0.1992,  0.1992,  0.1992,  ...,  0.0273,  0.0273,  0.0273],\n",
              "            [ 0.1992,  0.1992,  0.1992,  ...,  0.0273,  0.0273,  0.0273],\n",
              "            ...,\n",
              "            [ 0.1992,  0.1992,  0.1992,  ...,  0.0195,  0.0195,  0.0195],\n",
              "            [ 0.2070,  0.2070,  0.2070,  ...,  0.0195,  0.0195,  0.0195],\n",
              "            [ 0.2070,  0.2070,  0.2070,  ...,  0.0195,  0.0195,  0.0195]],\n",
              "  \n",
              "           [[ 0.6680,  0.6680,  0.6602,  ..., -0.0742, -0.0742, -0.0820],\n",
              "            [ 0.6602,  0.6602,  0.6602,  ..., -0.0742, -0.0742, -0.0742],\n",
              "            [ 0.6602,  0.6602,  0.6602,  ..., -0.0742, -0.0742, -0.0742],\n",
              "            ...,\n",
              "            [ 0.6758,  0.6758,  0.6758,  ..., -0.0742, -0.0742, -0.0742],\n",
              "            [ 0.6758,  0.6758,  0.6758,  ..., -0.0742, -0.0742, -0.0742],\n",
              "            [ 0.6758,  0.6758,  0.6758,  ..., -0.0820, -0.0742, -0.0742]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.5977, -0.5977, -0.5977,  ..., -0.1836, -0.1758, -0.1602],\n",
              "            [-0.5977, -0.5977, -0.5898,  ..., -0.1836, -0.1758, -0.1680],\n",
              "            [-0.5977, -0.5977, -0.5898,  ..., -0.1914, -0.1836, -0.1758],\n",
              "            ...,\n",
              "            [-0.5977, -0.5977, -0.5977,  ..., -0.4492, -0.4570, -0.4570],\n",
              "            [-0.5898, -0.5898, -0.5977,  ..., -0.4492, -0.4570, -0.4492],\n",
              "            [-0.5898, -0.5977, -0.5977,  ..., -0.4492, -0.4492, -0.4570]],\n",
              "  \n",
              "           [[-0.4180, -0.4180, -0.4180,  ..., -0.1367, -0.1289, -0.1211],\n",
              "            [-0.4180, -0.4180, -0.4180,  ..., -0.1367, -0.1289, -0.1211],\n",
              "            [-0.4258, -0.4258, -0.4180,  ..., -0.1445, -0.1367, -0.1289],\n",
              "            ...,\n",
              "            [-0.4180, -0.4180, -0.4180,  ..., -0.4180, -0.4180, -0.4180],\n",
              "            [-0.4180, -0.4180, -0.4180,  ..., -0.4180, -0.4180, -0.4180],\n",
              "            [-0.4180, -0.4180, -0.4180,  ..., -0.4180, -0.4180, -0.4180]],\n",
              "  \n",
              "           [[-0.0352, -0.0352, -0.0430,  ..., -0.0898, -0.0820, -0.0742],\n",
              "            [-0.0352, -0.0352, -0.0352,  ..., -0.0898, -0.0820, -0.0742],\n",
              "            [-0.0352, -0.0352, -0.0352,  ..., -0.0977, -0.0898, -0.0820],\n",
              "            ...,\n",
              "            [-0.0273, -0.0273, -0.0273,  ..., -0.3945, -0.3945, -0.3945],\n",
              "            [-0.0352, -0.0273, -0.0352,  ..., -0.3945, -0.3945, -0.3945],\n",
              "            [-0.0352, -0.0352, -0.0352,  ..., -0.3945, -0.3945, -0.3945]]],\n",
              "  \n",
              "  \n",
              "          ...,\n",
              "  \n",
              "  \n",
              "          [[[ 0.6523,  0.6602,  0.6602,  ...,  0.4023,  0.4102,  0.4180],\n",
              "            [ 0.6523,  0.6602,  0.6602,  ...,  0.3945,  0.4102,  0.4102],\n",
              "            [ 0.6523,  0.6602,  0.6602,  ...,  0.3867,  0.4102,  0.4102],\n",
              "            ...,\n",
              "            [ 0.6523,  0.6523,  0.6523,  ...,  0.4258,  0.4180,  0.4180],\n",
              "            [ 0.6602,  0.6523,  0.6523,  ...,  0.4180,  0.4102,  0.4180],\n",
              "            [ 0.6602,  0.6523,  0.6523,  ...,  0.4102,  0.4102,  0.4180]],\n",
              "  \n",
              "           [[ 0.8477,  0.8555,  0.8555,  ...,  0.4102,  0.3945,  0.4023],\n",
              "            [ 0.8477,  0.8555,  0.8555,  ...,  0.4023,  0.3945,  0.3945],\n",
              "            [ 0.8477,  0.8555,  0.8555,  ...,  0.3945,  0.3945,  0.3945],\n",
              "            ...,\n",
              "            [ 0.8477,  0.8477,  0.8477,  ...,  0.4180,  0.4102,  0.4102],\n",
              "            [ 0.8555,  0.8477,  0.8477,  ...,  0.4102,  0.4023,  0.4023],\n",
              "            [ 0.8555,  0.8477,  0.8477,  ...,  0.4023,  0.3945,  0.4023]],\n",
              "  \n",
              "           [[ 0.9961,  0.9961,  0.9961,  ...,  0.2852,  0.2773,  0.2852],\n",
              "            [ 0.9961,  0.9961,  0.9961,  ...,  0.2773,  0.2773,  0.2773],\n",
              "            [ 0.9961,  0.9961,  0.9961,  ...,  0.2695,  0.2773,  0.2773],\n",
              "            ...,\n",
              "            [ 0.9961,  0.9961,  0.9961,  ...,  0.2773,  0.2695,  0.2695],\n",
              "            [ 0.9961,  0.9961,  0.9961,  ...,  0.2695,  0.2773,  0.2773],\n",
              "            [ 0.9961,  0.9961,  0.9961,  ...,  0.2617,  0.2773,  0.2852]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0039, -0.0039, -0.0039,  ...,  0.0664,  0.0742,  0.0742],\n",
              "            [-0.0039, -0.0039, -0.0039,  ...,  0.0664,  0.0664,  0.0664],\n",
              "            [-0.0117, -0.0117, -0.0195,  ...,  0.0664,  0.0664,  0.0664],\n",
              "            ...,\n",
              "            [-0.0117, -0.0117, -0.0117,  ...,  0.0586,  0.0586,  0.0664],\n",
              "            [-0.0195, -0.0039, -0.0117,  ...,  0.0586,  0.0664,  0.0664],\n",
              "            [-0.0195, -0.0117, -0.0117,  ...,  0.0586,  0.0586,  0.0586]],\n",
              "  \n",
              "           [[ 0.3477,  0.3477,  0.3477,  ...,  0.0820,  0.0898,  0.0898],\n",
              "            [ 0.3477,  0.3477,  0.3477,  ...,  0.0820,  0.0820,  0.0820],\n",
              "            [ 0.3398,  0.3398,  0.3320,  ...,  0.0820,  0.0820,  0.0820],\n",
              "            ...,\n",
              "            [ 0.3398,  0.3398,  0.3398,  ...,  0.0742,  0.0742,  0.0820],\n",
              "            [ 0.3320,  0.3477,  0.3398,  ...,  0.0742,  0.0820,  0.0820],\n",
              "            [ 0.3320,  0.3398,  0.3398,  ...,  0.0742,  0.0742,  0.0742]],\n",
              "  \n",
              "           [[ 0.8555,  0.8555,  0.8555,  ..., -0.0898, -0.0820, -0.0820],\n",
              "            [ 0.8555,  0.8555,  0.8555,  ..., -0.0898, -0.0898, -0.0898],\n",
              "            [ 0.8477,  0.8477,  0.8398,  ..., -0.0898, -0.0898, -0.0898],\n",
              "            ...,\n",
              "            [ 0.8477,  0.8477,  0.8477,  ..., -0.1055, -0.1055, -0.0977],\n",
              "            [ 0.8555,  0.8711,  0.8633,  ..., -0.0977, -0.0898, -0.0898],\n",
              "            [ 0.8555,  0.8633,  0.8633,  ..., -0.0977, -0.0977, -0.0977]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.4883,  0.4883,  0.4883,  ..., -0.2773, -0.2852, -0.2930],\n",
              "            [ 0.4883,  0.4883,  0.4883,  ..., -0.2930, -0.2930, -0.2930],\n",
              "            [ 0.4961,  0.4961,  0.4883,  ..., -0.3008, -0.3008, -0.3008],\n",
              "            ...,\n",
              "            [ 0.4805,  0.4805,  0.4805,  ..., -0.2930, -0.3008, -0.3008],\n",
              "            [ 0.4805,  0.4805,  0.4805,  ..., -0.2930, -0.2930, -0.2930],\n",
              "            [ 0.4883,  0.4883,  0.4883,  ..., -0.2930, -0.2930, -0.2930]],\n",
              "  \n",
              "           [[ 0.5352,  0.5352,  0.5352,  ..., -0.2148, -0.2148, -0.2148],\n",
              "            [ 0.5352,  0.5352,  0.5352,  ..., -0.2227, -0.2148, -0.2148],\n",
              "            [ 0.5430,  0.5430,  0.5352,  ..., -0.2227, -0.2227, -0.2227],\n",
              "            ...,\n",
              "            [ 0.5273,  0.5273,  0.5273,  ..., -0.2305, -0.2227, -0.2227],\n",
              "            [ 0.5273,  0.5273,  0.5273,  ..., -0.2305, -0.2227, -0.2148],\n",
              "            [ 0.5352,  0.5352,  0.5352,  ..., -0.2305, -0.2305, -0.2305]],\n",
              "  \n",
              "           [[ 0.5352,  0.5352,  0.5352,  ..., -0.1914, -0.1992, -0.1992],\n",
              "            [ 0.5352,  0.5352,  0.5352,  ..., -0.1992, -0.1992, -0.1992],\n",
              "            [ 0.5430,  0.5430,  0.5352,  ..., -0.2070, -0.2070, -0.2070],\n",
              "            ...,\n",
              "            [ 0.5117,  0.5117,  0.5117,  ..., -0.2070, -0.2070, -0.2070],\n",
              "            [ 0.5117,  0.5117,  0.5117,  ..., -0.2070, -0.1992, -0.1992],\n",
              "            [ 0.5195,  0.5195,  0.5195,  ..., -0.2148, -0.2148, -0.2148]]]]),\n",
              "  tensor([[[[-0.2227, -0.2227, -0.2148,  ...,  0.4727,  0.4805,  0.4883],\n",
              "            [-0.2305, -0.2305, -0.2227,  ...,  0.4727,  0.4883,  0.4961],\n",
              "            [-0.2305, -0.2305, -0.2227,  ...,  0.4727,  0.4805,  0.4961],\n",
              "            ...,\n",
              "            [-0.2148, -0.2227, -0.2148,  ...,  0.3320,  0.3555,  0.3711],\n",
              "            [-0.2070, -0.2227, -0.2227,  ...,  0.3242,  0.3477,  0.3633],\n",
              "            [-0.2070, -0.2227, -0.2227,  ...,  0.3242,  0.3477,  0.3633]],\n",
              "  \n",
              "           [[-0.1602, -0.1602, -0.1523,  ...,  0.5273,  0.5352,  0.5430],\n",
              "            [-0.1680, -0.1680, -0.1602,  ...,  0.5273,  0.5430,  0.5508],\n",
              "            [-0.1680, -0.1680, -0.1602,  ...,  0.5273,  0.5352,  0.5508],\n",
              "            ...,\n",
              "            [-0.1758, -0.1758, -0.1758,  ...,  0.3867,  0.4102,  0.4258],\n",
              "            [-0.1680, -0.1836, -0.1836,  ...,  0.3789,  0.4023,  0.4180],\n",
              "            [-0.1680, -0.1836, -0.1836,  ...,  0.3789,  0.4023,  0.4180]],\n",
              "  \n",
              "           [[-0.1445, -0.1445, -0.1367,  ...,  0.6055,  0.6133,  0.6211],\n",
              "            [-0.1523, -0.1523, -0.1445,  ...,  0.6055,  0.6211,  0.6289],\n",
              "            [-0.1523, -0.1523, -0.1445,  ...,  0.6055,  0.6133,  0.6289],\n",
              "            ...,\n",
              "            [-0.1680, -0.1680, -0.1680,  ...,  0.4492,  0.4727,  0.4883],\n",
              "            [-0.1445, -0.1602, -0.1602,  ...,  0.4414,  0.4648,  0.4805],\n",
              "            [-0.1445, -0.1602, -0.1602,  ...,  0.4414,  0.4648,  0.4805]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.3867,  0.3867,  0.3867,  ...,  0.7227,  0.7227,  0.7227],\n",
              "            [ 0.3789,  0.3789,  0.3789,  ...,  0.7227,  0.7305,  0.7305],\n",
              "            [ 0.3867,  0.3789,  0.3711,  ...,  0.7227,  0.7227,  0.7227],\n",
              "            ...,\n",
              "            [ 0.3789,  0.3789,  0.3867,  ...,  0.7305,  0.7305,  0.7305],\n",
              "            [ 0.3789,  0.3789,  0.3867,  ...,  0.7227,  0.7227,  0.7227],\n",
              "            [ 0.3789,  0.3789,  0.3711,  ...,  0.7227,  0.7227,  0.7227]],\n",
              "  \n",
              "           [[ 0.4102,  0.4102,  0.4102,  ...,  0.9102,  0.9102,  0.9102],\n",
              "            [ 0.4023,  0.4023,  0.4023,  ...,  0.9102,  0.9180,  0.9180],\n",
              "            [ 0.4102,  0.4023,  0.3945,  ...,  0.9102,  0.9102,  0.9102],\n",
              "            ...,\n",
              "            [ 0.4023,  0.4023,  0.4102,  ...,  0.9180,  0.9180,  0.9180],\n",
              "            [ 0.4023,  0.4023,  0.4102,  ...,  0.9102,  0.9102,  0.9102],\n",
              "            [ 0.4023,  0.4023,  0.3945,  ...,  0.9102,  0.9102,  0.9102]],\n",
              "  \n",
              "           [[ 0.3242,  0.3242,  0.3242,  ...,  0.9961,  0.9961,  0.9961],\n",
              "            [ 0.3164,  0.3164,  0.3164,  ...,  0.9961,  0.9961,  0.9961],\n",
              "            [ 0.3242,  0.3164,  0.3086,  ...,  0.9961,  0.9961,  0.9961],\n",
              "            ...,\n",
              "            [ 0.3164,  0.3164,  0.3242,  ...,  0.9961,  0.9961,  0.9961],\n",
              "            [ 0.3242,  0.3320,  0.3398,  ...,  0.9961,  0.9961,  0.9961],\n",
              "            [ 0.3320,  0.3320,  0.3242,  ...,  0.9961,  0.9961,  0.9961]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.1758, -0.1680, -0.1680,  ...,  0.6758,  0.6758,  0.6758],\n",
              "            [-0.1758, -0.1758, -0.1758,  ...,  0.6758,  0.6758,  0.6836],\n",
              "            [-0.1680, -0.1758, -0.1758,  ...,  0.6836,  0.6836,  0.6836],\n",
              "            ...,\n",
              "            [-0.1758, -0.1836, -0.1758,  ...,  0.5742,  0.5820,  0.5898],\n",
              "            [-0.1758, -0.1836, -0.1758,  ...,  0.5820,  0.5898,  0.5977],\n",
              "            [-0.1758, -0.1836, -0.1836,  ...,  0.5820,  0.5898,  0.5977]],\n",
              "  \n",
              "           [[-0.1055, -0.0977, -0.0977,  ...,  0.7305,  0.7305,  0.7305],\n",
              "            [-0.1055, -0.1055, -0.1055,  ...,  0.7305,  0.7305,  0.7383],\n",
              "            [-0.0977, -0.1055, -0.1055,  ...,  0.7383,  0.7383,  0.7383],\n",
              "            ...,\n",
              "            [-0.1055, -0.1133, -0.1055,  ...,  0.6289,  0.6367,  0.6445],\n",
              "            [-0.1055, -0.1133, -0.1055,  ...,  0.6367,  0.6445,  0.6523],\n",
              "            [-0.1055, -0.1133, -0.1133,  ...,  0.6367,  0.6445,  0.6523]],\n",
              "  \n",
              "           [[-0.0664, -0.0586, -0.0586,  ...,  0.7773,  0.7773,  0.7773],\n",
              "            [-0.0664, -0.0664, -0.0664,  ...,  0.7773,  0.7773,  0.7852],\n",
              "            [-0.0586, -0.0664, -0.0664,  ...,  0.7852,  0.7852,  0.7852],\n",
              "            ...,\n",
              "            [-0.0664, -0.0742, -0.0664,  ...,  0.6758,  0.6836,  0.6914],\n",
              "            [-0.0664, -0.0742, -0.0664,  ...,  0.6836,  0.6914,  0.6992],\n",
              "            [-0.0664, -0.0742, -0.0742,  ...,  0.6836,  0.6914,  0.6992]]],\n",
              "  \n",
              "  \n",
              "          ...,\n",
              "  \n",
              "  \n",
              "          [[[-0.5117, -0.5273, -0.5195,  ..., -0.7539, -0.7695, -0.7617],\n",
              "            [-0.5195, -0.5273, -0.5195,  ..., -0.7617, -0.7539, -0.7539],\n",
              "            [-0.5352, -0.5352, -0.5273,  ..., -0.7148, -0.7070, -0.6992],\n",
              "            ...,\n",
              "            [-0.5742, -0.5742, -0.5820,  ..., -0.2852, -0.2852, -0.2852],\n",
              "            [-0.5742, -0.5820, -0.5820,  ..., -0.2852, -0.2852, -0.2852],\n",
              "            [-0.5742, -0.5820, -0.5742,  ..., -0.2852, -0.2852, -0.2930]],\n",
              "  \n",
              "           [[-0.6445, -0.6523, -0.6367,  ..., -0.8789, -0.8789, -0.8789],\n",
              "            [-0.6523, -0.6523, -0.6445,  ..., -0.8867, -0.8789, -0.8789],\n",
              "            [-0.6523, -0.6523, -0.6445,  ..., -0.8086, -0.8086, -0.8008],\n",
              "            ...,\n",
              "            [-0.3867, -0.3867, -0.3945,  ..., -0.3086, -0.3086, -0.3086],\n",
              "            [-0.3867, -0.3945, -0.3945,  ..., -0.3086, -0.3086, -0.3086],\n",
              "            [-0.3867, -0.3945, -0.3867,  ..., -0.3086, -0.3086, -0.3164]],\n",
              "  \n",
              "           [[-0.7852, -0.7930, -0.7852,  ..., -0.9648, -0.9648, -0.9648],\n",
              "            [-0.7930, -0.8008, -0.7852,  ..., -0.9648, -0.9570, -0.9570],\n",
              "            [-0.8008, -0.8008, -0.7930,  ..., -0.8789, -0.8711, -0.8633],\n",
              "            ...,\n",
              "            [-0.0117, -0.0117, -0.0195,  ..., -0.3789, -0.3789, -0.3789],\n",
              "            [-0.0117, -0.0195, -0.0195,  ..., -0.3789, -0.3711, -0.3789],\n",
              "            [-0.0117, -0.0195, -0.0195,  ..., -0.3789, -0.3711, -0.3789]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.6211, -0.6211, -0.6133,  ...,  0.0273,  0.0352,  0.0352],\n",
              "            [-0.6211, -0.6211, -0.6133,  ...,  0.0273,  0.0352,  0.0352],\n",
              "            [-0.6211, -0.6211, -0.6133,  ...,  0.0195,  0.0273,  0.0273],\n",
              "            ...,\n",
              "            [ 0.0117,  0.0117,  0.0117,  ...,  0.0195,  0.0195,  0.0195],\n",
              "            [ 0.0117,  0.0117,  0.0117,  ...,  0.0117,  0.0117,  0.0117],\n",
              "            [ 0.0117,  0.0117,  0.0117,  ...,  0.0117,  0.0117,  0.0117]],\n",
              "  \n",
              "           [[-0.6992, -0.6992, -0.6914,  ..., -0.0352, -0.0273, -0.0273],\n",
              "            [-0.6992, -0.6992, -0.6914,  ..., -0.0352, -0.0273, -0.0273],\n",
              "            [-0.6992, -0.6992, -0.6914,  ..., -0.0430, -0.0352, -0.0352],\n",
              "            ...,\n",
              "            [-0.0430, -0.0430, -0.0430,  ..., -0.0273, -0.0273, -0.0273],\n",
              "            [-0.0430, -0.0430, -0.0430,  ..., -0.0352, -0.0352, -0.0352],\n",
              "            [-0.0430, -0.0430, -0.0430,  ..., -0.0352, -0.0352, -0.0352]],\n",
              "  \n",
              "           [[-0.7695, -0.7695, -0.7617,  ..., -0.1289, -0.1211, -0.1133],\n",
              "            [-0.7695, -0.7695, -0.7617,  ..., -0.1289, -0.1211, -0.1133],\n",
              "            [-0.7695, -0.7695, -0.7617,  ..., -0.1367, -0.1289, -0.1211],\n",
              "            ...,\n",
              "            [-0.1680, -0.1680, -0.1680,  ..., -0.1211, -0.1211, -0.1211],\n",
              "            [-0.1680, -0.1680, -0.1680,  ..., -0.1289, -0.1289, -0.1289],\n",
              "            [-0.1680, -0.1680, -0.1680,  ..., -0.1289, -0.1289, -0.1289]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.0664,  0.0820,  0.0898,  ..., -0.0039,  0.0039,  0.0039],\n",
              "            [ 0.0586,  0.0664,  0.0898,  ...,  0.0039,  0.0039,  0.0117],\n",
              "            [ 0.0586,  0.0664,  0.0898,  ...,  0.0039,  0.0039,  0.0039],\n",
              "            ...,\n",
              "            [ 0.0586,  0.0742,  0.0664,  ...,  0.0039,  0.0039, -0.0039],\n",
              "            [ 0.0820,  0.0820,  0.0664,  ..., -0.0039, -0.0039,  0.0039],\n",
              "            [ 0.0664,  0.0664,  0.0586,  ...,  0.0039,  0.0039, -0.0039]],\n",
              "  \n",
              "           [[ 0.0977,  0.1133,  0.1211,  ...,  0.3008,  0.3086,  0.3086],\n",
              "            [ 0.0898,  0.0977,  0.1211,  ...,  0.3086,  0.3086,  0.3164],\n",
              "            [ 0.0898,  0.0977,  0.1211,  ...,  0.3086,  0.3086,  0.3086],\n",
              "            ...,\n",
              "            [ 0.0742,  0.0977,  0.0977,  ...,  0.3242,  0.3242,  0.3164],\n",
              "            [ 0.0977,  0.0977,  0.0977,  ...,  0.3164,  0.3164,  0.3242],\n",
              "            [ 0.0820,  0.0820,  0.0898,  ...,  0.3242,  0.3242,  0.3164]],\n",
              "  \n",
              "           [[ 0.0898,  0.1055,  0.1133,  ...,  0.7305,  0.7383,  0.7383],\n",
              "            [ 0.0820,  0.0898,  0.1133,  ...,  0.7383,  0.7383,  0.7461],\n",
              "            [ 0.0820,  0.0898,  0.1133,  ...,  0.7383,  0.7383,  0.7383],\n",
              "            ...,\n",
              "            [ 0.0508,  0.0742,  0.0820,  ...,  0.7305,  0.7305,  0.7305],\n",
              "            [ 0.0742,  0.0820,  0.0898,  ...,  0.7383,  0.7383,  0.7461],\n",
              "            [ 0.0586,  0.0664,  0.0820,  ...,  0.7461,  0.7461,  0.7383]]]])],\n",
              " tensor([[1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.]]),\n",
              " [('D-0',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-1'),\n",
              "  ('D-0',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-0',\n",
              "   'D-1',\n",
              "   'D-1',\n",
              "   'D-0')]]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = next(iter(train_loader))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SiameseInceptionResnetV1(\n",
            "  (conv2d_1a): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (conv2d_2a): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (conv2d_2b): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2d_3b): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (conv2d_4a): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (conv2d_4b): BasicConv2d(\n",
            "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (repeat_1): Sequential(\n",
            "    (0): Block35(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (branch2): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (1): Block35(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (branch2): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (2): Block35(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (branch2): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (3): Block35(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (branch2): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (4): Block35(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (branch2): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (mixed_6a): Mixed_6a(\n",
            "    (branch0): BasicConv2d(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (branch1): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (2): BasicConv2d(\n",
            "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (repeat_2): Sequential(\n",
            "    (0): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (1): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (2): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (3): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (4): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (5): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (6): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (7): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (8): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (9): Block17(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (mixed_7a): Mixed_7a(\n",
            "    (branch0): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch1): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (2): BasicConv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (repeat_3): Sequential(\n",
            "    (0): Block8(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (1): Block8(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (2): Block8(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (3): Block8(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (4): Block8(\n",
            "      (branch0): BasicConv2d(\n",
            "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (branch1): Sequential(\n",
            "        (0): BasicConv2d(\n",
            "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (1): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (2): BasicConv2d(\n",
            "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (block8): Block8(\n",
            "    (branch0): BasicConv2d(\n",
            "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (branch1): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (2): BasicConv2d(\n",
            "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
            "  (dropout): Dropout(p=0.6, inplace=False)\n",
            "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
            "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
            "  (sameclass): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(siamese)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define optimizer and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(siamese.parameters(), lr=0.001)\n",
        "scheduler = MultiStepLR(optimizer, [5, 10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define loss and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loss_fn = torch.nn.CrossEntropyLoss()\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "metrics = {\n",
        "    'fps': training.BatchTimer(),\n",
        "    'acc': training.accuracy\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i_batch, ((x1, x2), y, (class1, class2)) in enumerate(train_loader):\n",
        "#     print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 256, 256])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = siamese(x1, x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 256, 256])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.transpose(y, 0, 1)[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0400, 0.0771, 0.0691,  ..., 0.0203, 0.0129, 0.0392],\n",
              "        [0.0272, 0.0084, 0.0709,  ..., 0.0328, 0.0036, 0.0016],\n",
              "        [0.0659, 0.0359, 0.0602,  ..., 0.0716, 0.0102, 0.0472],\n",
              "        ...,\n",
              "        [0.0224, 0.0054, 0.0391,  ..., 0.1032, 0.0328, 0.0092],\n",
              "        [0.0085, 0.0873, 0.1174,  ..., 0.0889, 0.0205, 0.0093],\n",
              "        [0.0918, 0.0710, 0.0176,  ..., 0.0448, 0.0337, 0.0460]],\n",
              "       grad_fn=<AbsBackward0>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected input batch_size (32) to match target batch_size (1).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23920/1262812048.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Miniconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Miniconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[1;32m~\\Miniconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2844\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2846\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (32) to match target batch_size (1)."
          ]
        }
      ],
      "source": [
        "loss_fn(y_pred, torch.transpose(y, 0, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Initial\n",
            "----------\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Expected input batch_size (32) to match target batch_size (1).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24312/3619576380.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msiamese\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m pass_epoch(\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0msiamese\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mbatch_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_running\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\U339700\\Documents\\Palas\\code\\functions\\net_train.py\u001b[0m in \u001b[0;36mpass_epoch\u001b[1;34m(model, loss_fn, loader, optimizer, scheduler, batch_metrics, show_running, device, writer)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;31m# y_pred = torch.transpose(y_pred, 0, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mloss_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Miniconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Miniconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[1;32m~\\Miniconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2844\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2846\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (32) to match target batch_size (1)."
          ]
        }
      ],
      "source": [
        "writer = SummaryWriter()\n",
        "writer.iteration, writer.interval = 0, 10\n",
        "best_val = 10000000\n",
        "\n",
        "print('\\n\\nInitial')\n",
        "print('-' * 10)\n",
        "siamese.eval()\n",
        "pass_epoch(\n",
        "    siamese, loss_fn, val_loader,\n",
        "    batch_metrics=metrics, show_running=True, device=device,\n",
        "    writer=writer\n",
        ")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Train\n",
        "    siamese.train()\n",
        "    pass_epoch(\n",
        "        siamese, loss_fn, train_loader, optimizer, scheduler,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "\n",
        "    # Validation\n",
        "    siamese.eval()\n",
        "    answ = pass_epoch(\n",
        "        siamese, loss_fn, val_loader,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "    loss = answ[0]\n",
        "    # Save model\n",
        "    if loss < best_val:\n",
        "        best_val = loss\n",
        "        print('Saving best weights')\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state_dict\": siamese.state_dict(),\n",
        "                # \"backbone\": args.backbone,\n",
        "                \"optimizer_state_dict\": optimizer.state_dict()\n",
        "            },\n",
        "            os.path.join(model_dir, \"best.pth\")\n",
        "        )            \n",
        "\n",
        "    # Save model based on the frequency defined by \"args.save_after\"\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state_dict\": siamese.state_dict(),\n",
        "                # \"backbone\": args.backbone,\n",
        "                \"optimizer_state_dict\": optimizer.state_dict()\n",
        "            },\n",
        "            os.path.join(model_dir, \"epoch_{}.pth\".format(epoch + 1))\n",
        "        ) \n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(siamese, 'C:/Users/U339700/Documents/Palas/models/nuevo.pth')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "01-Computer_Vision_and_feature_engineering.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a6d3716578bd93e5c5dcbe415e208f64cee43eed67c86e2a7b3ceb93a1cd614a"
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit ('main': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
